{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wirschtl_AI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpcTL4f2G9WE"
      },
      "source": [
        "# **Installing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PM2h7czt2s0f"
      },
      "source": [
        "!pip install --quiet transformers == 4.5.0\n",
        "!pip install --quiet sentencepiece == 0.1.95\n",
        "!pip install --quiet textwrap3 == 0.9.2\n",
        "!pip install --quiet nltk == 3.2.5\n",
        "!pip install --quiet git+https://github.com/boudinfl/pke.git@dc4d5f21e0ffe64c4df93c46146d29d1c522476b\n",
        "!pip install --quiet flashtext == 2.7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imbR470g15Fq"
      },
      "source": [
        "# **Setup Transformer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cXs7fnvCarm"
      },
      "source": [
        "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.corpus import wordnet as wn\n",
        "from textwrap import wrap\n",
        "import numpy as np\n",
        "import torch\n",
        "import nltk\n",
        "\n",
        "\n",
        "nltk.download( 'punkt' )\n",
        "nltk.download( 'brown' )\n",
        "nltk.download( 'wordnet' )\n",
        "\n",
        "\n",
        "summaryModel = T5ForConditionalGeneration.from_pretrained( 't5-base' )\n",
        "summaryTokenizer = T5Tokenizer.from_pretrained( 't5-base' )\n",
        "\n",
        "device = torch.device( \"cuda\" if torch.cuda.is_available() else \"cpu\" )\n",
        "summaryModel = summaryModel.to( device )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Summarize Text**"
      ],
      "metadata": {
        "id": "l4Cvij4ty8f9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JaEy5Xw_UMf"
      },
      "source": [
        "def PostProcesstext (content):\n",
        "    final = \"\"\n",
        "    for sent in sent_tokenize(content):\n",
        "        sent  = sent.capitalize()\n",
        "        final = final + \" \" + sent\n",
        "    return final\n",
        "\n",
        "\n",
        "def Summerize( text, model, tokenizer ):\n",
        "  text = text.strip().replace( \"\\n\", \" \" )\n",
        "  text = \"Summarization: \"+ text\n",
        "\n",
        "  max_len = 512\n",
        "  encoding = tokenizer.encode_plus(text, max_length = max_len, pad_to_max_length = False, truncation = True, return_tensors = \"pt\" ).to( device )\n",
        "\n",
        "  input_ids, attention_mask = encoding[ \"input_ids\" ], encoding[ \"attention_mask\" ]\n",
        "\n",
        "  outs = model.generate(input_ids = input_ids,\n",
        "                                  attention_mask = attention_mask,\n",
        "                                  early_stopping = True,\n",
        "                                  num_beams = 3,\n",
        "                                  num_return_sequences = 1,\n",
        "                                  no_repeat_ngram_size = 2,\n",
        "                                  min_length = 75,\n",
        "                                  max_length = 300)\n",
        "\n",
        "\n",
        "  dec = [ tokenizer.decode( ids, skip_special_tokens = True ) for ids in outs ]\n",
        "  summary = dec[0]\n",
        "  summary = PostProcesstext(summary)\n",
        "  summary = summary.strip()\n",
        "\n",
        "  return summary\n",
        "\n",
        "\n",
        "text = \"\"\"How does a teacher create a test? \n",
        "Probably he will look at the material and create questions from it. \n",
        "Wirschtl-Learner works on the same principle. \n",
        "He looks at the material and creates questions from it. \n",
        "Furthermore, with Wirschtl-Learner they can summarize their material and search for keywords in it.\"\"\"\n",
        "\n",
        "summarizedText = Summerize( text, summaryModel, summaryTokenizer )\n",
        "\n",
        "\n",
        "print( \"\\noriginal Text >>\" )\n",
        "for wrp in wrap( text, 150 ):\n",
        "  print( wrp )\n",
        "print( \"\\n\" )\n",
        "\n",
        "print( \"Summarized Text >>\" )\n",
        "for wrp in wrap( summarizedText, 150 ):\n",
        "  print( wrp )\n",
        "print( \"\\n\" )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXbq7b2WCaZ_"
      },
      "source": [
        "# **Question generation with T5**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CuKlpL1Cj6C"
      },
      "source": [
        "question_model     = T5ForConditionalGeneration.from_pretrained( 'ramsrigouthamg/t5_squad_v1' )\n",
        "question_tokenizer = T5Tokenizer.from_pretrained( 'ramsrigouthamg/t5_squad_v1' )\n",
        "question_model     = question_model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uzA4uLJ_P48"
      },
      "source": [
        "def GetQuestion( context, answer, model, tokenizer ):\n",
        "    text = \"context: {} answer: {}\".format(context,answer)\n",
        "    encoding = tokenizer.encode_plus(text,max_length=384, pad_to_max_length=False,truncation=True, return_tensors=\"pt\").to(device)\n",
        "    input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
        "\n",
        "    outs = model.generate(input_ids = input_ids,\n",
        "                                    attention_mask = attention_mask,\n",
        "                                    early_stopping = True,\n",
        "                                    num_beams = 5,\n",
        "                                    num_return_sequences = 1,\n",
        "                                    no_repeat_ngram_size = 2,\n",
        "                                    max_length = 72)\n",
        "\n",
        "    dec = [ tokenizer.decode(ids,skip_special_tokens = True) for ids in outs]\n",
        "\n",
        "    question = dec[0].replace( \"Question:\",\"\" )\n",
        "    question= question.strip()\n",
        "    return question"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GenerateQuestions( context, answerLength, numQuestions ):\n",
        "    data = []\n",
        "    sentences = context.split( \".\" )\n",
        "\n",
        "    for q in range( numQuestions ):\n",
        "        splittedContext = sentences[ np.random.randint( 0, len( sentences ) ) ].split( \" \" )\n",
        "\n",
        "        try:\n",
        "            splittedContext.remove( \"\\n\" )\n",
        "            splittedContext.remove( \".\" )\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        while True:\n",
        "            try:\n",
        "                splittedContext.remove( \"\" )\n",
        "            except:\n",
        "                break\n",
        "\n",
        "        for i in range( numQuestions ):\n",
        "            limit = len( splittedContext ) - answerLength\n",
        "            \n",
        "            if limit <= 0:\n",
        "                limit = 1\n",
        "            rIndex = np.random.randint( 0, len( splittedContext ) - answerLength )\n",
        "            \n",
        "            answer = \" \"\n",
        "            for _ in range( rIndex, rIndex + answerLength, 1 ):\n",
        "                answer += splittedContext[ _ ] + \" \"\n",
        "            \n",
        "            ques = GetQuestion( context, answer, question_model, question_tokenizer )\n",
        "            ques = ques.replace( \"question: \", \"\" )\n",
        "            data.append( { \"Question\": ques, \"Answer\": answer.capitalize() } )\n",
        "    return data\n",
        "\n",
        "def SaveQuestions( questions, fileName ):\n",
        "    file = open( fileName, \"w+\" )\n",
        "    for question in questions:\n",
        "        file.writelines( question[ \"Question\" ] + \";\" + question[ \"Answer\" ] )\n",
        "    file.close()"
      ],
      "metadata": {
        "id": "t_rEZGpzxZTS"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"\"\"Accenture emerged on January 1, 2001, through a name change from Andersen Consulting, a management consultancy founded in 1989. \n",
        "             The company was originally an affiliate of Arthur Andersen, the accounting firm involved in the Enron bankruptcy. \n",
        "             The name change came after the company lost the rights to the Andersen name in 2000 as part of a complete breakup.\n",
        "             The new name Accenture is a made-up word from Accent on the future.\n",
        "             After becoming a public company, Accenture has been listed on the NYSE (New York Stock Exchange) under the symbol \"ACN\" since July 19, 2001. \n",
        "             The board of directors includes Wulf von Schimmelmann, the former chairman of Postbank.\n",
        "             Since September 1, 2009, the Group has been operating as a public limited company under Irish law and at the same time moved its registered office from the Bermuda Islands to Dublin.\n",
        "             Accenture reported fiscal 2020 earnings of about $5.19 billion on annual revenue of about $44.33 billion, representing 4% year-over-year growth. \n",
        "             Accenture's shares were trading at $278.34 apiece on April 1, 2021. \n",
        "             Accenture's market capitalization was estimated at $185.13 billion as of April 2021.\"\"\"\n",
        "\n",
        "answers = GenerateQuestions( context, 4, 4 )\n",
        "print( answers )\n",
        "SaveQuestions( answers, \"C:/Wurschtl_AI/Questions/questions.txt\" )"
      ],
      "metadata": {
        "id": "wqGg9f5bc9B-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Get similar words**"
      ],
      "metadata": {
        "id": "-dvSoZyBtu1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Jeck similarity between every word in the files\n",
        "# If similarity > 0.98 two words are similar \n",
        "\n",
        "import gensim\n",
        "\n",
        "searchWord   = \"Benzin\"\n",
        "similarWords = []\n",
        "\n",
        "allWords = []\n",
        "\n",
        "word2vec = gensim.models.Word2Vec.load_word2vec_format( 'C:/Wurschtl_AI/model/GoogleNews-vectors-negative300.bin', binary = True )  \n",
        "\n",
        "for word in allWords:\n",
        "    sim = word2vec.similarity( searchWord, word )\n",
        "    if sim > 0.98:\n",
        "        similarWords.append( word )\n",
        "\n",
        "print( f\"Similar words to {0} are {1}\".format( similarWords ) )"
      ],
      "metadata": {
        "id": "oGFAJk1zru_I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}